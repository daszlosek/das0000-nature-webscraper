---
title: "Web Scraper"
output: html_notebook
---



```{r}
#install.packages("rvest")

library(rvest)


rm(list=ls())

packages = c('rmarkdown', 'plyr', 'dplyr','ggplot2', 'readr', 'tidyr', 'stringr',  'knitr', 'sparklyr', 'shiny', 'data.table', 'zoo','fasttime',"twitteR","openssl","httpuv" , 'rvest', 'httr','jsonlite','lubridate')

package.check <- lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
        install.packages(x, dependencies = TRUE)
        library(x, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)
    }
})


```


```{r}

url_nat <- 'http://api.nature.com'
# Construct API request
repos <- GET(url = url_nat)

names(repos)
#check to see if api is working or if i fucked up
status_code(repos) # 200..looking good


repo_content <- content(repos)

head(repos$headers,2)

repo_df <- lapply(repo_content, function(x) {
  df <- data_frame(repo        = x$name,
                   address     = x$html_url,
                   commits     = x$git_commits_url)
}) %>% bind_rows()
```


```{r API tutorial}

# Save username as variable
username <- 'hadley'

# Save base enpoint as variable
url_git <- 'https://api.github.com/'

# Construct API request
repos <- GET(url = paste0(url_git,'users/',username,'/repos'))


# Examine response components
names(repos)

status_code(repos)

# Process API request content 
repo_content <- content(repos)

# Apply function across all list elements to extract the name and address of each repo
repo_df <- lapply(repo_content, function(x) {
  df <- data_frame(repo        = x$name,
                   address     = x$html_url,
                   commits     = x$git_commits_url)
}) %>% bind_rows()

repos
```






























```{r}

lego_movie <- read_html("http://www.imdb.com/title/tt1490017/")

lego_movie %>%
  html_node("strong span") %>%
  html_text() %>%
  as.numeric()


vignette("selectorgadget")
```


```{r}
page=read_html("http://www.yelp.com/search?find_loc=New+York,+NY,+USA")
page %>% html_nodes(".biz-name") %>% html_attr('href')
```


```{r}

nsmb <- read_html("https://www.nature.com/nsmb/volumes/25/issues/10") 

```


```{r}


nsmb_node1 <-  nsmb %>% html_node(".pb30:nth-child(1)") %>% html_text()  %>% 
        # Trim additional white space
        str_trim() %>%                       
        # Convert the list into a vector
        unlist()
nsmb1 <- str_trim(sapply(strsplit(nsmb_node1, "\n"), "[", 8)) %>% print()

```



```{r}


nsmb_node1 <-  nsmb %>% html_node(".pb30:nth-child(1)") %>% html_text()  %>% 
        # Trim additional white space
        str_trim() %>%                       
        # Convert the list into a vector
        unlist()
nsmb1 <- str_trim(sapply(strsplit(nsmb_node1, "\n"), "[", 8)) %>% print()

nsmb_node2 <-  nsmb %>% html_node(".pb30:nth-child(2)") %>% html_text()  %>% 
        # Trim additional white space
        str_trim() %>%                       
        # Convert the list into a vector
        unlist()
nsmb2 <- str_trim(sapply(strsplit(nsmb_node2, "\n"), "[", 8)) %>% print()


nsmb_node3 <-  nsmb %>% html_node(".pb30:nth-child(3)") %>% html_text()  %>% 
        # Trim additional white space
        str_trim() %>%                       
        # Convert the list into a vector
        unlist()
nsmb3 <- str_trim(sapply(strsplit(nsmb_node3, "\n"), "[", 8)) %>% print()

nsmb_node4 <-  nsmb %>% html_node(".pb30:nth-child(4)") %>% html_text()  %>% 
        # Trim additional white space
        str_trim() %>%                       
        # Convert the list into a vector
        unlist()
nsmb4 <- str_trim(sapply(strsplit(nsmb_node4, "\n"), "[", 8)) %>% print()

nsmb_node5 <-  nsmb %>% html_node(".pb30:nth-child(5)") %>% html_text()  %>% 
        # Trim additional white space
        str_trim() %>%                       
        # Convert the list into a vector
        unlist()
nsmb5 <- str_trim(sapply(strsplit(nsmb_node5, "\n"), "[", 8)) %>% print()

nsmb_node6 <-  nsmb %>% html_node(".pb30:nth-child(6)") %>% html_text()  %>% 
        # Trim additional white space
        str_trim() %>%                       
        # Convert the list into a vector
        unlist()
nsmb6 <- str_trim(sapply(strsplit(nsmb_node6, "\n"), "[", 8)) %>% print()

nsmb_node7 <-  nsmb %>% html_node(".pb30:nth-child(7)") %>% html_text()  %>% 
        # Trim additional white space
        str_trim() %>%                       
        # Convert the list into a vector
        unlist()
nsmb7 <- str_trim(sapply(strsplit(nsmb_node7, "\n"), "[", 8)) %>% print()

dat <- rbind(nsmb1,nsmb2,nsmb3,nsmb4,nsmb5,nsmb6,nsmb7) %>% data.frame()

```


```{r}
url  <- "http://api.epdb.eu"


```

